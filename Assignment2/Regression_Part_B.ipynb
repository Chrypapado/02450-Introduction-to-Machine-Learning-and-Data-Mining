{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error  \n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "from data_preprocess import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Regression Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new DataFrame with Selected Features\n",
    "data_fs = data[['male', 'age', 'BPMeds', 'prevalentHyp', 'sysBP', 'diaBP', 'heartRate', 'glucose', 'TenYearCHD', 'educ4']]\n",
    "\n",
    "#DataFrame to NumPy Array\n",
    "data_np_fs = data_fs.to_numpy()\n",
    "\n",
    "#Splitting the Predicted Value from the Attributes\n",
    "idx_y = list(data_fs.columns).index('sysBP')\n",
    "idx_X = list(range(0, idx_y)) + list(range(idx_y + 1, len(data_fs.columns)))\n",
    "X = data_np_fs[:, idx_X]\n",
    "y = data_np_fs[:, idx_y]\n",
    "attributeNames = list(data_fs.columns[idx_X])\n",
    "N, M = X.shape\n",
    "\n",
    "#Normalize the Data\n",
    "X = stats.zscore(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "K1 = 5\n",
    "CV1 = model_selection.KFold(n_splits=K1,shuffle=True, random_state=0)\n",
    "\n",
    "K2 = 5\n",
    "CV2 = model_selection.KFold(n_splits=K2,shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====================================ANN=====================================#\n",
    "inner_ANN_error = np.empty((K1,1))\n",
    "outer_ANN_error = []\n",
    "k_hidden = np.empty((K1,1))\n",
    "opt_k1_hidden = []\n",
    "\n",
    "#Parameters for Neural Network Classifier\n",
    "n_hidden_units = [85, 90]      \n",
    "n_replicates = 1        \n",
    "max_iter = 10000\n",
    "\n",
    "#==========================Baseline Linear Regression=========================#\n",
    "baseline_error = np.zeros(K1)\n",
    "\n",
    "#========================Regularized Linear Regression========================#\n",
    "rlr_error = np.zeros(K1)\n",
    "lambdas_opt = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outer Crossvalidation fold: 1/5\n",
      "\n",
      "Inner Crossvalidation fold: 1/5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrypapa/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([2584])) that is different to the input size (torch.Size([2584, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/chrypapa/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t1000\t3256.1252\t0.00229149\n",
      "\t\t2000\t865.0876\t0.0003993157\n",
      "\t\t3000\t715.3054\t0.00011637304\n",
      "\t\t4000\t627.9025\t0.00012693339\n",
      "\t\t5000\t552.1935\t0.00012267569\n",
      "\t\t6000\t503.0681\t7.0849266e-05\n",
      "\t\t7000\t480.30972\t2.28729e-05\n",
      "\t\t8000\t475.21704\t2.7613746e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8312\t474.94788\t9.638178e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t2926.6357\t0.002304998\n",
      "\t\t2000\t870.35803\t0.00029647702\n",
      "\t\t3000\t743.20215\t0.00012645584\n",
      "\t\t4000\t648.22156\t0.00014601753\n",
      "\t\t5000\t557.1951\t0.00012891197\n",
      "\t\t6000\t501.72327\t7.6512646e-05\n",
      "\t\t7000\t479.26053\t2.0885418e-05\n",
      "\t\t8000\t475.04694\t1.8629909e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8169\t474.93088\t9.638524e-07\n",
      "\n",
      "Inner Crossvalidation fold: 2/5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3413.6643\t0.0021153283\n",
      "\t\t2000\t904.834\t0.00041258402\n",
      "\t\t3000\t722.82776\t0.00013668873\n",
      "\t\t4000\t620.1189\t0.00012960883\n",
      "\t\t5000\t547.7169\t0.00010340153\n",
      "\t\t6000\t499.36258\t6.275918e-05\n",
      "\t\t7000\t479.9487\t1.952024e-05\n",
      "\t\t8000\t475.60718\t2.309953e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8498\t475.21848\t9.63269e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t2896.4072\t0.0024778962\n",
      "\t\t2000\t723.96606\t0.00039675826\n",
      "\t\t3000\t605.62274\t9.109756e-05\n",
      "\t\t4000\t551.7664\t0.00010275332\n",
      "\t\t5000\t509.60477\t7.071895e-05\n",
      "\t\t6000\t483.60318\t2.6692527e-05\n",
      "\t\t7000\t476.1565\t5.447747e-06\n",
      "\t\tFinal loss:\n",
      "\t\t7725\t475.20847\t9.632893e-07\n",
      "\n",
      "Inner Crossvalidation fold: 3/5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3590.0654\t0.0022339108\n",
      "\t\t2000\t1024.7566\t0.00042579632\n",
      "\t\t3000\t772.10486\t0.00026411648\n",
      "\t\t4000\t640.76294\t0.0001555254\n",
      "\t\t5000\t556.2957\t0.00012879129\n",
      "\t\t6000\t504.40335\t7.0903705e-05\n",
      "\t\t7000\t481.3411\t2.4979428e-05\n",
      "\t\t8000\t475.73932\t3.2073742e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8363\t475.3935\t9.629143e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3063.1157\t0.0022267248\n",
      "\t\t2000\t990.06354\t0.0003189868\n",
      "\t\t3000\t798.5465\t0.00019845662\n",
      "\t\t4000\t673.2657\t0.00016623433\n",
      "\t\t5000\t566.86926\t0.00013812231\n",
      "\t\t6000\t503.5481\t9.665578e-05\n",
      "\t\t7000\t480.01312\t2.1551987e-05\n",
      "\t\t8000\t475.44525\t1.797243e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8115\t475.36526\t9.629715e-07\n",
      "\n",
      "Inner Crossvalidation fold: 4/5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3227.3186\t0.0020978514\n",
      "\t\t2000\t1123.8198\t0.00025019993\n",
      "\t\t3000\t963.95197\t0.00013687399\n",
      "\t\t4000\t825.0514\t0.0001752957\n",
      "\t\t5000\t682.72437\t0.00019690812\n",
      "\t\t6000\t565.5743\t0.00016821451\n",
      "\t\t7000\t496.45026\t8.900292e-05\n",
      "\t\t8000\t471.22876\t2.2083253e-05\n",
      "\t\t9000\t467.1646\t1.5678002e-06\n",
      "\t\tFinal loss:\n",
      "\t\t9096\t467.1057\t9.799992e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3040.9011\t0.002283556\n",
      "\t\t2000\t847.88434\t0.0004099318\n",
      "\t\t3000\t672.4929\t0.0001392965\n",
      "\t\t4000\t587.855\t0.00010454275\n",
      "\t\t5000\t526.126\t8.920268e-05\n",
      "\t\t6000\t488.28064\t5.4059645e-05\n",
      "\t\t7000\t470.6648\t1.5626028e-05\n",
      "\t\t8000\t467.3392\t1.8937168e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8160\t467.23032\t9.797378e-07\n",
      "\n",
      "Inner Crossvalidation fold: 5/5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3307.9067\t0.0022753172\n",
      "\t\t2000\t870.40686\t0.00038468456\n",
      "\t\t3000\t696.04626\t0.00018788085\n",
      "\t\t4000\t599.1331\t0.00011938025\n",
      "\t\t5000\t537.9571\t9.0644164e-05\n",
      "\t\t6000\t500.05103\t5.3519507e-05\n",
      "\t\t7000\t483.50085\t1.5400541e-05\n",
      "\t\t8000\t480.27084\t1.3979316e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8127\t480.1931\t9.532899e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3133.6013\t0.0023092995\n",
      "\t\t2000\t828.79767\t0.0004390141\n",
      "\t\t3000\t665.59735\t0.00024441196\n",
      "\t\t4000\t573.0688\t0.00012715177\n",
      "\t\t5000\t521.15704\t8.513514e-05\n",
      "\t\t6000\t492.6581\t3.8032624e-05\n",
      "\t\t7000\t481.82834\t8.0437385e-06\n",
      "\t\tFinal loss:\n",
      "\t\t7793\t480.35495\t9.529687e-07\n",
      "\n",
      "Error rate (Baseline Linear Regression) 1/5: 508.58\n",
      "\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrypapa/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([3230])) that is different to the input size (torch.Size([3230, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t1000\t3466.0925\t0.0021222567\n",
      "\t\t2000\t1017.9851\t0.00039825443\n",
      "\t\t3000\t814.8799\t0.00013824776\n",
      "\t\t4000\t699.8299\t0.00014048246\n",
      "\t\t5000\t587.88007\t0.00014636824\n",
      "\t\t6000\t516.0315\t8.858235e-05\n",
      "\t\t7000\t485.5484\t3.4253044e-05\n",
      "\t\t8000\t477.4819\t5.0491476e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8544\t476.7882\t9.600976e-07\n",
      "\n",
      "Error rate (ANN) 1/5: 476.7882080078125\n",
      "\n",
      "\n",
      "Error rate (Regularized Linear Regression) 1/5: 139.48\n",
      "Optimal lambda: 10.0\n",
      "\n",
      "\n",
      "Outer Crossvalidation fold: 2/5\n",
      "\n",
      "Inner Crossvalidation fold: 1/5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrypapa/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([2584])) that is different to the input size (torch.Size([2584, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t1000\t3452.3174\t0.0022299844\n",
      "\t\t2000\t894.265\t0.00040661506\n",
      "\t\t3000\t734.02783\t0.00012978188\n",
      "\t\t4000\t637.3568\t0.00012811439\n",
      "\t\t5000\t561.0394\t0.00012172055\n",
      "\t\t6000\t506.52017\t7.825795e-05\n",
      "\t\t7000\t481.1999\t2.676242e-05\n",
      "\t\t8000\t475.27274\t3.2747332e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8363\t474.9271\t9.6386e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t2984.4333\t0.0022879024\n",
      "\t\t2000\t913.1285\t0.00030550736\n",
      "\t\t3000\t761.7748\t0.00021211887\n",
      "\t\t4000\t646.95667\t0.00014800062\n",
      "\t\t5000\t559.9743\t0.00013622688\n",
      "\t\t6000\t502.57782\t7.6868266e-05\n",
      "\t\t7000\t479.48572\t2.1957554e-05\n",
      "\t\t8000\t475.05902\t1.927183e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8175\t474.9337\t9.638467e-07\n",
      "\n",
      "Inner Crossvalidation fold: 2/5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3295.8298\t0.002119026\n",
      "\t\t2000\t938.7106\t0.00042589597\n",
      "\t\t3000\t733.93915\t0.000146924\n",
      "\t\t4000\t634.80237\t0.00013180192\n",
      "\t\t5000\t553.11066\t0.00015402335\n",
      "\t\t6000\t497.65036\t5.8560352e-05\n",
      "\t\t7000\t479.62335\t1.9024475e-05\n",
      "\t\t8000\t475.38544\t2.3752257e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8250\t475.183\t9.633409e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t2897.4268\t0.0023428574\n",
      "\t\t2000\t846.81055\t0.00037854668\n",
      "\t\t3000\t697.93195\t0.00012215474\n",
      "\t\t4000\t599.2603\t0.00012750097\n",
      "\t\t5000\t531.4722\t0.00011643589\n",
      "\t\t6000\t490.79254\t4.7254718e-05\n",
      "\t\t7000\t477.27673\t1.1253499e-05\n",
      "\t\tFinal loss:\n",
      "\t\t7946\t475.1074\t9.634942e-07\n",
      "\n",
      "Inner Crossvalidation fold: 3/5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3199.9548\t0.002155181\n",
      "\t\t2000\t928.0513\t0.00041560622\n",
      "\t\t3000\t759.8861\t0.00018695339\n",
      "\t\t4000\t647.30054\t0.00013321661\n",
      "\t\t5000\t566.8029\t0.0001264041\n",
      "\t\t6000\t509.2257\t8.191675e-05\n",
      "\t\t7000\t482.0194\t2.8426248e-05\n",
      "\t\t8000\t475.77454\t3.3354218e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8360\t475.40472\t9.628916e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3270.1946\t0.0021843647\n",
      "\t\t2000\t984.275\t0.00037966867\n",
      "\t\t3000\t766.2779\t0.00018037802\n",
      "\t\t4000\t647.0577\t0.00014694022\n",
      "\t\t5000\t562.2373\t0.00013090338\n",
      "\t\t6000\t504.6469\t7.854842e-05\n",
      "\t\t7000\t480.44376\t2.362872e-05\n",
      "\t\t8000\t475.55878\t2.2460165e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8223\t475.38513\t9.629313e-07\n",
      "\n",
      "Inner Crossvalidation fold: 4/5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3243.3481\t0.0020799339\n",
      "\t\t2000\t1047.8398\t0.00030384862\n",
      "\t\t3000\t879.6273\t0.00014541509\n",
      "\t\t4000\t738.03503\t0.00016099008\n",
      "\t\t5000\t625.13855\t0.00016048554\n",
      "\t\t6000\t538.5548\t0.00013382644\n",
      "\t\t7000\t485.65027\t6.2331994e-05\n",
      "\t\t8000\t469.27316\t1.3266267e-05\n",
      "\t\tFinal loss:\n",
      "\t\t8856\t467.11398\t9.799818e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t2950.4055\t0.0022839992\n",
      "\t\t2000\t892.5722\t0.0002511694\n",
      "\t\t3000\t775.387\t0.00012152232\n",
      "\t\t4000\t674.05725\t0.0002213431\n",
      "\t\t5000\t577.2179\t0.00014442031\n",
      "\t\t6000\t507.66675\t9.509037e-05\n",
      "\t\t7000\t476.01212\t3.7054742e-05\n",
      "\t\t8000\t467.7223\t5.0892572e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8489\t467.1144\t9.79981e-07\n",
      "\n",
      "Inner Crossvalidation fold: 5/5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3413.7183\t0.0021141556\n",
      "\t\t2000\t930.15497\t0.00054138555\n",
      "\t\t3000\t705.42255\t0.00017526453\n",
      "\t\t4000\t605.5939\t0.0001288882\n",
      "\t\t5000\t541.943\t9.200439e-05\n",
      "\t\t6000\t499.4046\t5.6521636e-05\n",
      "\t\t7000\t482.4881\t1.2776423e-05\n",
      "\t\t8000\t480.33566\t1.397743e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8210\t480.20013\t9.5327596e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t2972.979\t0.0023231811\n",
      "\t\t2000\t798.9919\t0.00040668878\n",
      "\t\t3000\t632.5056\t0.00012388732\n",
      "\t\t4000\t556.2796\t8.480659e-05\n",
      "\t\t5000\t514.7997\t6.401883e-05\n",
      "\t\t6000\t488.4272\t2.6553858e-05\n",
      "\t\t7000\t480.83765\t4.5696415e-06\n",
      "\t\tFinal loss:\n",
      "\t\t7539\t480.1979\t9.532804e-07\n",
      "\n",
      "Error rate (Baseline Linear Regression) 2/5: 453.53\n",
      "\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrypapa/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([3230])) that is different to the input size (torch.Size([3230, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t1000\t2968.29\t0.00243465\n",
      "\t\t2000\t731.61176\t0.00047329965\n",
      "\t\t3000\t596.68634\t0.0001040183\n",
      "\t\t4000\t543.75214\t7.823082e-05\n",
      "\t\t5000\t512.7367\t4.5827535e-05\n",
      "\t\t6000\t496.3064\t2.0168114e-05\n",
      "\t\t7000\t490.90292\t2.9218038e-06\n",
      "\t\tFinal loss:\n",
      "\t\t7342\t490.58148\t9.953102e-07\n",
      "\n",
      "Error rate (ANN) 2/5: 490.58148193359375\n",
      "\n",
      "\n",
      "Error rate (Regularized Linear Regression) 2/5: 119.61\n",
      "Optimal lambda: 10.0\n",
      "\n",
      "\n",
      "Outer Crossvalidation fold: 3/5\n",
      "\n",
      "Inner Crossvalidation fold: 1/5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrypapa/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([2584])) that is different to the input size (torch.Size([2584, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t1000\t3267.031\t0.002163187\n",
      "\t\t2000\t870.7568\t0.0005072259\n",
      "\t\t3000\t687.412\t0.00012855107\n",
      "\t\t4000\t600.86536\t0.000107763444\n",
      "\t\t5000\t539.84344\t9.824022e-05\n",
      "\t\t6000\t498.1154\t6.0159673e-05\n",
      "\t\t7000\t479.1313\t1.7706496e-05\n",
      "\t\t8000\t475.283\t2.1189016e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8237\t475.10464\t9.634998e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3110.2573\t0.0021942211\n",
      "\t\t2000\t991.79865\t0.00032802293\n",
      "\t\t3000\t814.5288\t0.00016632378\n",
      "\t\t4000\t678.5175\t0.00016755566\n",
      "\t\t5000\t577.52673\t0.00014941441\n",
      "\t\t6000\t507.76218\t9.122668e-05\n",
      "\t\t7000\t480.1917\t2.5039217e-05\n",
      "\t\t8000\t475.1038\t2.1197009e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8206\t474.9515\t9.638104e-07\n",
      "\n",
      "Inner Crossvalidation fold: 2/5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3474.4224\t0.0021112317\n",
      "\t\t2000\t961.5313\t0.00043139418\n",
      "\t\t3000\t773.0007\t0.00014360531\n",
      "\t\t4000\t658.10693\t0.00013408915\n",
      "\t\t5000\t568.1105\t0.00013062434\n",
      "\t\t6000\t508.45456\t8.000062e-05\n",
      "\t\t7000\t482.04584\t2.8804518e-05\n",
      "\t\t8000\t475.52725\t3.7863872e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8408\t475.0933\t9.635228e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3053.0056\t0.00234051\n",
      "\t\t2000\t891.36395\t0.0003324671\n",
      "\t\t3000\t728.7137\t0.00015375493\n",
      "\t\t4000\t612.8033\t0.00013135503\n",
      "\t\t5000\t537.3476\t0.0001065323\n",
      "\t\t6000\t494.87164\t5.7964244e-05\n",
      "\t\t7000\t478.22455\t1.5506641e-05\n",
      "\t\t8000\t475.1304\t1.2203666e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8069\t475.0907\t9.635281e-07\n",
      "\n",
      "Inner Crossvalidation fold: 3/5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3722.2034\t0.002003567\n",
      "\t\t2000\t1220.3885\t0.000452212\n",
      "\t\t3000\t890.12164\t0.00021224597\n",
      "\t\t4000\t736.22516\t0.00018508777\n",
      "\t\t5000\t614.37335\t0.0001738242\n",
      "\t\t6000\t528.29083\t0.00011679047\n",
      "\t\t7000\t486.63486\t4.446044e-05\n",
      "\t\t8000\t476.20645\t6.1520996e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8569\t475.3915\t9.629184e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3184.4043\t0.0021013273\n",
      "\t\t2000\t1088.9274\t0.0003361912\n",
      "\t\t3000\t873.06085\t0.00018354837\n",
      "\t\t4000\t714.8729\t0.00017789824\n",
      "\t\t5000\t599.72864\t0.00016850485\n",
      "\t\t6000\t514.54535\t0.000104967316\n",
      "\t\t7000\t482.10748\t3.069973e-05\n",
      "\t\t8000\t475.6925\t3.1435363e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8326\t475.38455\t9.629325e-07\n",
      "\n",
      "Inner Crossvalidation fold: 4/5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3352.424\t0.0020401028\n",
      "\t\t2000\t1066.541\t0.00030790197\n",
      "\t\t3000\t886.702\t0.00017549563\n",
      "\t\t4000\t743.1014\t0.00015742936\n",
      "\t\t5000\t624.72266\t0.00016303406\n",
      "\t\t6000\t535.2244\t0.00013294896\n",
      "\t\t7000\t485.13007\t6.070058e-05\n",
      "\t\t8000\t469.2791\t1.2745867e-05\n",
      "\t\tFinal loss:\n",
      "\t\t8891\t467.11093\t9.1465574e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3188.6804\t0.0022089803\n",
      "\t\t2000\t936.0614\t0.0004433225\n",
      "\t\t3000\t740.9588\t0.00015557879\n",
      "\t\t4000\t627.3234\t0.00013356759\n",
      "\t\t5000\t544.7215\t0.00014272924\n",
      "\t\t6000\t491.67828\t6.4546744e-05\n",
      "\t\t7000\t471.72687\t2.0119218e-05\n",
      "\t\t8000\t467.38092\t2.35061e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8274\t467.1634\t9.798782e-07\n",
      "\n",
      "Inner Crossvalidation fold: 5/5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3571.1858\t0.0020651736\n",
      "\t\t2000\t1125.852\t0.00048561572\n",
      "\t\t3000\t853.81915\t0.00021312248\n",
      "\t\t4000\t699.8258\t0.00016751153\n",
      "\t\t5000\t578.72736\t0.00014330563\n",
      "\t\t6000\t513.5955\t8.5319094e-05\n",
      "\t\t7000\t485.20227\t2.3334098e-05\n",
      "\t\t8000\t480.37872\t2.2870086e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8233\t480.19293\t9.532902e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3145.16\t0.0023220803\n",
      "\t\t2000\t801.8597\t0.0005657619\n",
      "\t\t3000\t599.55206\t0.00014494399\n",
      "\t\t4000\t538.5726\t7.1278e-05\n",
      "\t\t5000\t500.46732\t8.206987e-05\n",
      "\t\t6000\t483.64508\t1.2556567e-05\n",
      "\t\t7000\t480.37033\t1.334113e-06\n",
      "\t\tFinal loss:\n",
      "\t\t7159\t480.2712\t9.531349e-07\n",
      "\n",
      "Error rate (Baseline Linear Regression) 3/5: 505.77\n",
      "\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrypapa/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([3230])) that is different to the input size (torch.Size([3230, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t1000\t3223.0344\t0.002116399\n",
      "\t\t2000\t913.47485\t0.00038237797\n",
      "\t\t3000\t754.74835\t0.000124279\n",
      "\t\t4000\t658.49896\t0.00018849249\n",
      "\t\t5000\t564.1052\t0.00012246534\n",
      "\t\t6000\t506.43387\t8.417579e-05\n",
      "\t\t7000\t482.1929\t2.2277283e-05\n",
      "\t\t8000\t477.5488\t2.42837e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8249\t477.34344\t9.589809e-07\n",
      "\n",
      "Error rate (ANN) 3/5: 477.34344482421875\n",
      "\n",
      "\n",
      "Error rate (Regularized Linear Regression) 3/5: 134.19\n",
      "Optimal lambda: 10.0\n",
      "\n",
      "\n",
      "Outer Crossvalidation fold: 4/5\n",
      "\n",
      "Inner Crossvalidation fold: 1/5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrypapa/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([2584])) that is different to the input size (torch.Size([2584, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t1000\t3847.8145\t0.002032452\n",
      "\t\t2000\t1101.6222\t0.00037096368\n",
      "\t\t3000\t883.82526\t0.00018849266\n",
      "\t\t4000\t738.9284\t0.00016872241\n",
      "\t\t5000\t619.08746\t0.00017181094\n",
      "\t\t6000\t528.45056\t0.00011998836\n",
      "\t\t7000\t485.73993\t4.6552632e-05\n",
      "\t\t8000\t474.68143\t7.3290807e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8636\t473.64688\t9.664652e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3139.4614\t0.0022269664\n",
      "\t\t2000\t1051.5714\t0.00028119175\n",
      "\t\t3000\t879.6162\t0.00015103573\n",
      "\t\t4000\t733.4907\t0.00022345722\n",
      "\t\t5000\t607.65594\t0.00016721064\n",
      "\t\t6000\t519.3747\t0.00012748927\n",
      "\t\t7000\t482.1758\t3.594822e-05\n",
      "\t\t8000\t474.0773\t4.312944e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8393\t473.6375\t9.664843e-07\n",
      "\n",
      "Inner Crossvalidation fold: 2/5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrypapa/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([2585])) that is different to the input size (torch.Size([2585, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t1000\t3447.428\t0.0021391518\n",
      "\t\t2000\t988.5449\t0.00040023934\n",
      "\t\t3000\t790.4174\t0.00014777512\n",
      "\t\t4000\t672.83954\t0.00021004671\n",
      "\t\t5000\t578.0476\t0.00013217928\n",
      "\t\t6000\t512.5011\t7.7404286e-05\n",
      "\t\t7000\t487.28323\t2.680407e-05\n",
      "\t\t8000\t481.1985\t3.424665e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8385\t480.81448\t9.520579e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t2990.9739\t0.0021221654\n",
      "\t\t2000\t989.61633\t0.00032436996\n",
      "\t\t3000\t815.7925\t0.00015073355\n",
      "\t\t4000\t680.72375\t0.0001656682\n",
      "\t\t5000\t574.9592\t0.0001426528\n",
      "\t\t6000\t512.25146\t8.530467e-05\n",
      "\t\t7000\t486.11407\t2.4671395e-05\n",
      "\t\t8000\t480.98013\t2.3475975e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8244\t480.78745\t9.5211146e-07\n",
      "\n",
      "Inner Crossvalidation fold: 3/5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3480.6\t0.001988178\n",
      "\t\t2000\t1224.7236\t0.00035460587\n",
      "\t\t3000\t984.1774\t0.00016332456\n",
      "\t\t4000\t801.66785\t0.0001802557\n",
      "\t\t5000\t658.9937\t0.00019677606\n",
      "\t\t6000\t548.0087\t0.0001563478\n",
      "\t\t7000\t485.64822\t7.144267e-05\n",
      "\t\t8000\t468.00775\t1.25196675e-05\n",
      "\t\tFinal loss:\n",
      "\t\t8805\t466.07434\t9.821679e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3173.6252\t0.0021835922\n",
      "\t\t2000\t1166.8773\t0.00028321127\n",
      "\t\t3000\t961.6475\t0.00021841383\n",
      "\t\t4000\t790.6698\t0.00019503181\n",
      "\t\t5000\t641.11444\t0.00020930462\n",
      "\t\t6000\t536.1794\t0.0001609346\n",
      "\t\t7000\t480.22095\t5.7826277e-05\n",
      "\t\t8000\t467.18127\t8.295924e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8615\t466.09113\t9.821324e-07\n",
      "\n",
      "Inner Crossvalidation fold: 4/5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3135.4824\t0.002117219\n",
      "\t\t2000\t957.0973\t0.00038490177\n",
      "\t\t3000\t798.42523\t0.00012649952\n",
      "\t\t4000\t681.80786\t0.00014079448\n",
      "\t\t5000\t584.66034\t0.00013799011\n",
      "\t\t6000\t516.3944\t9.738307e-05\n",
      "\t\t7000\t482.00766\t3.9126193e-05\n",
      "\t\t8000\t472.82095\t5.8088926e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8546\t472.04028\t9.697546e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3025.9985\t0.0021359758\n",
      "\t\t2000\t956.3576\t0.0003189366\n",
      "\t\t3000\t793.25415\t0.00014209306\n",
      "\t\t4000\t672.9314\t0.00025734154\n",
      "\t\t5000\t573.7764\t0.00015634601\n",
      "\t\t6000\t506.9388\t8.680047e-05\n",
      "\t\t7000\t478.8226\t2.9954375e-05\n",
      "\t\t8000\t472.38998\t3.5531255e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8370\t472.0268\t9.697823e-07\n",
      "\n",
      "Inner Crossvalidation fold: 5/5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3500.9773\t0.0022266207\n",
      "\t\t2000\t882.0504\t0.00059183664\n",
      "\t\t3000\t655.6144\t0.0001839241\n",
      "\t\t4000\t574.3856\t0.00010688778\n",
      "\t\t5000\t523.00946\t7.783278e-05\n",
      "\t\t6000\t491.1594\t4.094447e-05\n",
      "\t\t7000\t482.08173\t6.1404253e-06\n",
      "\t\tFinal loss:\n",
      "\t\t7820\t480.90903\t9.5187073e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3046.2312\t0.0022511669\n",
      "\t\t2000\t780.70386\t0.00050923735\n",
      "\t\t3000\t609.4505\t0.0001202631\n",
      "\t\t4000\t544.6681\t8.616622e-05\n",
      "\t\t5000\t501.42178\t4.807874e-05\n",
      "\t\t6000\t486.97223\t1.7922728e-05\n",
      "\t\t7000\t481.728\t4.877944e-06\n",
      "\t\tFinal loss:\n",
      "\t\t7541\t480.764\t9.5215785e-07\n",
      "\n",
      "Error rate (Baseline Linear Regression) 4/5: 478.3\n",
      "\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrypapa/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([3231])) that is different to the input size (torch.Size([3231, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t1000\t2877.1726\t0.0023198696\n",
      "\t\t2000\t859.1692\t0.00027946325\n",
      "\t\t3000\t722.117\t0.00011933157\n",
      "\t\t4000\t624.6993\t0.0001237747\n",
      "\t\t5000\t553.5908\t0.000110681955\n",
      "\t\t6000\t505.73438\t6.818305e-05\n",
      "\t\t7000\t487.42166\t1.5214052e-05\n",
      "\t\t8000\t484.3454\t1.3231638e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8069\t484.30643\t8.821806e-07\n",
      "\n",
      "Error rate (ANN) 4/5: 484.3064270019531\n",
      "\n",
      "\n",
      "Error rate (Regularized Linear Regression) 4/5: 144.54\n",
      "Optimal lambda: 10.0\n",
      "\n",
      "\n",
      "Outer Crossvalidation fold: 5/5\n",
      "\n",
      "Inner Crossvalidation fold: 1/5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrypapa/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([2584])) that is different to the input size (torch.Size([2584, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t1000\t3284.5388\t0.0021647809\n",
      "\t\t2000\t1023.9979\t0.00032664658\n",
      "\t\t3000\t857.9006\t0.00014561218\n",
      "\t\t4000\t723.594\t0.00019295557\n",
      "\t\t5000\t602.77856\t0.00016289492\n",
      "\t\t6000\t523.4382\t0.00011286025\n",
      "\t\t7000\t484.61185\t4.307184e-05\n",
      "\t\t8000\t474.48135\t6.367418e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8578\t473.63367\t9.664922e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t2942.8928\t0.0022697493\n",
      "\t\t2000\t865.4732\t0.00035298048\n",
      "\t\t3000\t718.037\t0.0001268081\n",
      "\t\t4000\t625.76886\t0.00013380185\n",
      "\t\t5000\t550.84436\t0.00011588641\n",
      "\t\t6000\t499.1608\t7.0425755e-05\n",
      "\t\t7000\t477.7163\t1.8908779e-05\n",
      "\t\t8000\t473.78098\t2.1256192e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8187\t473.6481\t9.664627e-07\n",
      "\n",
      "Inner Crossvalidation fold: 2/5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrypapa/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([2585])) that is different to the input size (torch.Size([2585, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t1000\t3416.2192\t0.0021205102\n",
      "\t\t2000\t972.3087\t0.00039995785\n",
      "\t\t3000\t768.0911\t0.0002755827\n",
      "\t\t4000\t648.6761\t0.00013349856\n",
      "\t\t5000\t557.2433\t0.00010787594\n",
      "\t\t6000\t509.49146\t6.732095e-05\n",
      "\t\t7000\t485.9959\t2.618437e-05\n",
      "\t\t8000\t481.03455\t2.2204495e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8263\t480.83557\t8.250808e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t2954.736\t0.00233708\n",
      "\t\t2000\t778.82874\t0.0003992816\n",
      "\t\t3000\t638.3459\t0.00010784158\n",
      "\t\t4000\t564.09644\t0.00010353655\n",
      "\t\t5000\t517.8592\t6.446555e-05\n",
      "\t\t6000\t491.8466\t3.3442186e-05\n",
      "\t\t7000\t482.34323\t8.414762e-06\n",
      "\t\tFinal loss:\n",
      "\t\t7827\t480.80368\t9.520793e-07\n",
      "\n",
      "Inner Crossvalidation fold: 3/5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3545.665\t0.0021230672\n",
      "\t\t2000\t1028.661\t0.00036062408\n",
      "\t\t3000\t835.90265\t0.00015528318\n",
      "\t\t4000\t692.81494\t0.00016489104\n",
      "\t\t5000\t587.87854\t0.00015020893\n",
      "\t\t6000\t515.1158\t0.000107101885\n",
      "\t\t7000\t477.75363\t4.5223034e-05\n",
      "\t\t8000\t467.12817\t7.316929e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8647\t466.07648\t9.821633e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3179.1648\t0.0022083141\n",
      "\t\t2000\t962.0658\t0.00035292885\n",
      "\t\t3000\t763.4682\t0.00021780157\n",
      "\t\t4000\t638.9396\t0.0001519583\n",
      "\t\t5000\t553.8422\t0.00013200594\n",
      "\t\t6000\t496.16287\t8.192085e-05\n",
      "\t\t7000\t471.4489\t2.498572e-05\n",
      "\t\t8000\t466.3011\t2.5523907e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8252\t466.08936\t9.821362e-07\n",
      "\n",
      "Inner Crossvalidation fold: 4/5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3329.0579\t0.0021300514\n",
      "\t\t2000\t957.70575\t0.00038554886\n",
      "\t\t3000\t784.44324\t0.00013155429\n",
      "\t\t4000\t672.9282\t0.00013140825\n",
      "\t\t5000\t579.45776\t0.00013638569\n",
      "\t\t6000\t512.80975\t8.652082e-05\n",
      "\t\t7000\t481.11453\t3.5837234e-05\n",
      "\t\t8000\t472.62158\t4.261658e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8489\t472.0667\t9.697003e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t2925.965\t0.0023071861\n",
      "\t\t2000\t846.21216\t0.000331316\n",
      "\t\t3000\t709.3273\t0.00012673049\n",
      "\t\t4000\t617.2061\t0.00012873745\n",
      "\t\t5000\t543.41376\t0.00010803826\n",
      "\t\t6000\t496.66083\t6.672537e-05\n",
      "\t\t7000\t476.3598\t2.0179796e-05\n",
      "\t\t8000\t472.17682\t2.1328408e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8283\t471.97937\t9.698797e-07\n",
      "\n",
      "Inner Crossvalidation fold: 5/5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3383.9106\t0.0021447358\n",
      "\t\t2000\t899.98615\t0.00045817107\n",
      "\t\t3000\t706.0459\t0.00019835524\n",
      "\t\t4000\t606.2544\t0.00012512438\n",
      "\t\t5000\t539.7442\t0.000107189895\n",
      "\t\t6000\t495.25528\t5.6563862e-05\n",
      "\t\t7000\t482.78217\t1.0366644e-05\n",
      "\t\tFinal loss:\n",
      "\t\t7947\t480.7066\t9.522716e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t3179.206\t0.0022363435\n",
      "\t\t2000\t924.51416\t0.00044978058\n",
      "\t\t3000\t690.14374\t0.00023421826\n",
      "\t\t4000\t584.66583\t0.00012786537\n",
      "\t\t5000\t527.5678\t8.525743e-05\n",
      "\t\t6000\t493.84708\t6.210073e-05\n",
      "\t\t7000\t481.9714\t7.59813e-06\n",
      "\t\tFinal loss:\n",
      "\t\t7744\t480.75052\t9.5218456e-07\n",
      "\n",
      "Error rate (Baseline Linear Regression) 5/5: 467.46\n",
      "\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrypapa/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([3231])) that is different to the input size (torch.Size([3231, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t1000\t3414.6753\t0.0022375004\n",
      "\t\t2000\t894.66046\t0.00053423055\n",
      "\t\t3000\t664.6392\t0.00017702077\n",
      "\t\t4000\t584.2642\t0.0001033052\n",
      "\t\t5000\t531.43835\t7.72874e-05\n",
      "\t\t6000\t495.1941\t2.8594346e-05\n",
      "\t\t7000\t488.18005\t5.813671e-06\n",
      "\t\tFinal loss:\n",
      "\t\t7943\t486.94424\t9.400732e-07\n",
      "\n",
      "Error rate (ANN) 5/5: 486.9442443847656\n",
      "\n",
      "\n",
      "Error rate (Regularized Linear Regression) 5/5: 117.11\n",
      "Optimal lambda: 10.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#=====================================ANN=====================================#\n",
    "#Setup Figure for Display of Learning Curves and Error Rates in Fold\n",
    "lc = []\n",
    "summaries, summaries_axes = plt.subplots(1,2, figsize=(10,5))\n",
    "color_list = ['tab:orange', 'tab:green', 'tab:purple', \n",
    "              'tab:brown', 'tab:pink', 'tab:gray', \n",
    "              'tab:olive', 'tab:cyan', 'tab:red', 'tab:blue']\n",
    "\n",
    "for (k1, (train_index1, test_index1)) in enumerate(CV1.split(X,y)): \n",
    "    print('\\nOuter Crossvalidation fold: {0}/{1}'.format(k1+1,K1))\n",
    "    \n",
    "    #Extract Training and Test set for Current CV Fold\n",
    "    X_train1 = X[train_index1,:]\n",
    "    y_train1 = y[train_index1]\n",
    "    X_test1 = X[test_index1,:]\n",
    "    y_test1 = y[test_index1]\n",
    "\n",
    "    #=====================================ANN=====================================#\n",
    "    #Convert to Tensors\n",
    "    X_train_ANN1 = torch.tensor(X[train_index1,:], dtype=torch.float)\n",
    "    y_train_ANN1 = torch.tensor(y[train_index1], dtype=torch.float)\n",
    "    X_test_ANN1 = torch.tensor(X[test_index1,:], dtype=torch.float)\n",
    "    y_test_ANN1 = torch.tensor(y[test_index1], dtype=torch.uint8)\n",
    "    \n",
    "    #Initialize Variables\n",
    "    inner_ANN_error_hidden = np.empty((K2,len(n_hidden_units)))\n",
    "    \n",
    "    for (k2, (train_index2, test_index2)) in enumerate(CV2.split(X_train1, y_train1)):\n",
    "        print('\\nInner Crossvalidation fold: {0}/{1}'.format(k2+1,K2))\n",
    "                                                      \n",
    "        #Extract Training and Test set for Current CV Fold\n",
    "        X_train2 = X[train_index2,:]\n",
    "        y_train2 = y[train_index2]\n",
    "        X_test2 = X[test_index2,:]\n",
    "        y_test2 = y[test_index2]\n",
    "    \n",
    "        #Convert to Tensors\n",
    "        X_train_ANN2 = torch.tensor(X[train_index2,:], dtype=torch.float)\n",
    "        y_train_ANN2 = torch.tensor(y[train_index2], dtype=torch.float)\n",
    "        X_test_ANN2 = torch.tensor(X[test_index2,:], dtype=torch.float)\n",
    "        y_test_ANN2 = torch.tensor(y[test_index2], dtype=torch.uint8)\n",
    "        \n",
    "        #Train the Net on Different Number of Hidden Units\n",
    "        for i, number in enumerate(n_hidden_units):\n",
    "            \n",
    "            #Define the Model\n",
    "            model = lambda: torch.nn.Sequential(torch.nn.Linear(M, number), \n",
    "                                                torch.nn.Tanh(),\n",
    "                                                torch.nn.Linear(number, 1))\n",
    "            loss_fn = torch.nn.MSELoss() \n",
    "        \n",
    "            #Train the Net on Training Data\n",
    "            net, final_loss, learning_curve = train_neural_net(model, loss_fn, \n",
    "                                                               X=X_train_ANN2,\n",
    "                                                               y=y_train_ANN2,\n",
    "                                                               n_replicates=n_replicates,\n",
    "                                                               max_iter=max_iter)\n",
    "    \n",
    "            #Determine Estimated Class Labels for Test Set\n",
    "            y_test_ANN2_pred = net(X_test_ANN2)\n",
    "            \n",
    "            #Turn to NumPy\n",
    "            y_test_ANN2_np = y_test_ANN2.type(torch.float).data.numpy()\n",
    "            y_test_ANN2_pred_np = y_test_ANN2_pred.type(torch.float).data.numpy().reshape((y_test_ANN2.shape[0],))\n",
    "    \n",
    "            #Determine Errors and Errors\n",
    "            inner_ANN_error_hidden[k2,i] = np.square(y_test_ANN2_np-y_test_ANN2_pred_np).sum(axis=0)/y_test_ANN2_np.shape[0]\n",
    "\n",
    "        inner_ANN_error[k2] = np.min(np.mean(inner_ANN_error_hidden,axis=0))\n",
    "        k_hidden[k2] = n_hidden_units[np.argmin(np.mean(inner_ANN_error_hidden,axis=0))] \n",
    "    \n",
    "    #==========================Baseline Linear Regression=========================#\n",
    "    baseline_error[k1] = np.square(y_test1 - y_test1.mean()).sum() / len(y_test1)\n",
    "    print('\\nError rate (Baseline Linear Regression) {0}/{1}: {2}\\n'.format(k1+1, K1, np.round(baseline_error[k1], decimals = 2)))   \n",
    "    \n",
    "    #========================Regularized Linear Regression========================#     \n",
    "    #Initialize Variables\n",
    "    lambdas = np.power(10.,range(-5,9))\n",
    "    error_lambdas_k1 = np.zeros(len(lambdas))\n",
    "    \n",
    "    for l in range(len(lambdas)):\n",
    "        error_lambdas_k2 = np.zeros(K2)\n",
    "        \n",
    "        for (k2 , (train_index2, test_index2)) in enumerate(CV2.split(X_train1, y_train1)):\n",
    "            \n",
    "            #Extract Training and Test Set for Current CV Fold\n",
    "            X_train2 = X[train_index2,:]\n",
    "            y_train2 = y[train_index2]\n",
    "            X_test2 = X[test_index2,:]\n",
    "            y_test2 = y[test_index2]\n",
    "\n",
    "            rlr_model = lm.Ridge(alpha = lambdas[l], fit_intercept = True)\n",
    "            rlr_model = rlr_model.fit(X_train2, y_train2)\n",
    "\n",
    "            y_pred2 = rlr_model.predict(X_test2).T\n",
    "            error_lambdas_k2[k2] = np.square(y_test2 - y_pred2).sum() / len(y_pred2)\n",
    "        \n",
    "        error_lambdas_k1[l] = np.sum(error_lambdas_k2) / len(error_lambdas_k2)\n",
    "    \n",
    "    #=====================================ANN=====================================#    \n",
    "    opt_k2_hidden = int(k_hidden[inner_ANN_error.argmin()].item())\n",
    "    \n",
    "    #Define the model\n",
    "    model = lambda: torch.nn.Sequential(torch.nn.Linear(M, opt_k2_hidden), \n",
    "                                        torch.nn.Tanh(),   \n",
    "                                        torch.nn.Linear(opt_k2_hidden, 1))\n",
    "    loss_fn = torch.nn.MSELoss() \n",
    "\n",
    "    #Train the Net on Training Data\n",
    "    net, final_loss, learning_curve = train_neural_net(model, loss_fn,\n",
    "                                                       X=X_train_ANN1,\n",
    "                                                       y=y_train_ANN1,\n",
    "                                                       n_replicates=n_replicates,\n",
    "                                                       max_iter=max_iter)\n",
    "    \n",
    "    print('\\nError rate (ANN) {0}/{1}: {2}\\n'.format(k1+1, K1, final_loss))\n",
    "    lc.append(learning_curve)\n",
    "    \n",
    "    #Determine Estimated Class Labels for Test Set\n",
    "    y_test_ANN1_pred = net(X_test_ANN1)\n",
    "    \n",
    "    #Turn to NumPy\n",
    "    y_test_ANN1_np = y_test_ANN1.type(torch.float).data.numpy()\n",
    "    y_test_ANN1_pred_np = y_test_ANN1_pred.type(torch.float).data.numpy().reshape((y_test_ANN1.shape[0],))\n",
    "  \n",
    "    #Determine Errors and Errors\n",
    "    mse = np.square(y_test_ANN1_np-y_test_ANN1_pred_np).sum(axis=0)/y_test_ANN1_np.shape[0]\n",
    "    outer_ANN_error.append(mse) \n",
    "    opt_k1_hidden.append(opt_k2_hidden)\n",
    "    \n",
    "    # Display the learning curve for the best net in the current fold\n",
    "    h, = summaries_axes[0].plot(learning_curve, color=color_list[k1])\n",
    "    h.set_label('CV fold {0}'.format(k1+1))\n",
    "    summaries_axes[0].set_xlabel('Iterations')\n",
    "    summaries_axes[0].set_xlim((0, max_iter))\n",
    "    summaries_axes[0].set_ylabel('Loss')\n",
    "    summaries_axes[0].set_title('Learning curves')\n",
    "    \n",
    "    #========================Regularized Linear Regression========================# \n",
    "    min_error = np.min(error_lambdas_k1)\n",
    "    lambdas_opt_idx = np.argmin(error_lambdas_k1)\n",
    "    lambdas_opt.append(lambdas[lambdas_opt_idx])\n",
    "    \n",
    "    rlr_model = lm.Ridge(alpha = lambdas[lambdas_opt_idx], fit_intercept = True)\n",
    "    rlr_model = rlr_model.fit(X_train1, y_train1)\n",
    "    \n",
    "    y_pred1 = rlr_model.predict(X_test1).T\n",
    "    rlr_error[k1] = np.square(y_test1 - y_pred1).sum() / len(y_test1)\n",
    "    \n",
    "    print('\\nError rate (Regularized Linear Regression) {0}/{1}: {2}'.format(k1+1, K1, np.round(rlr_error[k1], decimals = 2)))\n",
    "    print('Optimal lambda: {0}\\n'.format(lambdas_opt[k1]))\n",
    "    \n",
    "#=====================================ANN=====================================#\n",
    "# Display the MSE across folds\n",
    "summaries_axes[1].bar(np.arange(1, K1+1), np.squeeze(np.asarray(outer_ANN_error)), color=color_list)\n",
    "summaries_axes[1].set_xlabel('Fold');\n",
    "summaries_axes[1].set_xticks(np.arange(1, K1+1))\n",
    "summaries_axes[1].set_ylabel('MSE');\n",
    "summaries_axes[1].set_title('Test mean-squared-error')\n",
    "\n",
    "plt.savefig('Learning Curves.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Generalization Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalization Error of ANN for 1 Fold: \t491.84, \t Hidden Units: 85\n",
      "Generalization Error of RLR for 1 Fold: \t139.48, \t Lambda: 10.0\n",
      "Generalization Error of BLR for 1 Fold: \t508.58\n",
      "\n",
      "Generalization Error of ANN for 2 Fold: \t455.68, \t Hidden Units: 90\n",
      "Generalization Error of RLR for 2 Fold: \t119.61, \t Lambda: 10.0\n",
      "Generalization Error of BLR for 2 Fold: \t453.53\n",
      "\n",
      "Generalization Error of ANN for 3 Fold: \t513.01, \t Hidden Units: 85\n",
      "Generalization Error of RLR for 3 Fold: \t134.19, \t Lambda: 10.0\n",
      "Generalization Error of BLR for 3 Fold: \t505.77\n",
      "\n",
      "Generalization Error of ANN for 4 Fold: \t482.67, \t Hidden Units: 90\n",
      "Generalization Error of RLR for 4 Fold: \t144.54, \t Lambda: 10.0\n",
      "Generalization Error of BLR for 4 Fold: \t478.30\n",
      "\n",
      "Generalization Error of ANN for 5 Fold: \t470.16, \t Hidden Units: 85\n",
      "Generalization Error of RLR for 5 Fold: \t117.11, \t Lambda: 10.0\n",
      "Generalization Error of BLR for 5 Fold: \t467.46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(K1): \n",
    "    print('Generalization Error of ANN for {0} Fold: \\t{1:.2f}, \\t Hidden Units: {2}'.format(i+1, outer_ANN_error[i], opt_k1_hidden[i]))\n",
    "    print('Generalization Error of RLR for {0} Fold: \\t{1:.2f}, \\t Lambda: {2}'.format(i+1, rlr_error[i], lambdas_opt[i]))\n",
    "    print('Generalization Error of BLR for {0} Fold: \\t{1:.2f}\\n'.format(i+1, baseline_error[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagram of Best Neural Net in Last Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#weights = [net[i].weight.data.numpy().T for i in [0,2]]\n",
    "#biases = [net[i].bias.data.numpy() for i in [0,2]]\n",
    "#tf =  [str(net[i]) for i in [1,2]]\n",
    "#draw_neural_net(weights, biases, tf, attribute_names=attributeNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Variables\n",
    "alpha = 0.05\n",
    "length = len(y_test1)\n",
    "y_true = np.array(y_test1).reshape(length,1)\n",
    "y_rlr = np.array(y_pred1).reshape(length,1)\n",
    "y_ann = list(float(i) for i in y_test_ANN1_pred_np)\n",
    "y_ann = np.array(y_ann).reshape(length,1)\n",
    "\n",
    "#Compute z and Confidence Interval of ANN\n",
    "zANN = np.abs(y_true - y_ann) ** 2 \n",
    "ciANN = stats.t.interval(1-alpha, df=len(zANN)-1, loc=np.mean(zANN), scale=stats.sem(zANN))  \n",
    "\n",
    "#Compute z and Confidence Interval of BLR\n",
    "zBASE = np.abs(y_true - y_test1.mean()) ** 2\n",
    "ciBASE = stats.t.interval(1-alpha, df=len(zBASE)-1, loc=np.mean(zBASE), scale=stats.sem(zBASE)) \n",
    "\n",
    "#Compute z and Confidence Interval of RLR\n",
    "zLIN = np.abs(y_true - y_rlr) ** 2\n",
    "ciLIN = stats.t.interval(1-alpha, df=len(zLIN)-1, loc=np.mean(zLIN), scale=stats.sem(zLIN)) \n",
    "\n",
    "#Compare ANN and Baseline\n",
    "zANBA = zBASE - zANN\n",
    "ciANBA = stats.t.interval(1-alpha, len(zANBA)-1, loc=np.mean(zANBA), scale=stats.sem(zANBA))  \n",
    "p_ANBA = stats.t.cdf( -np.abs( np.mean(zANBA) )/stats.sem(zANBA), df=len(zANBA)-1) \n",
    "\n",
    "#Compare ANN and RLR\n",
    "zANLI = zANN - zLIN\n",
    "ciANLI = stats.t.interval(1-alpha, len(zANLI)-1, loc=np.mean(zANLI), scale=stats.sem(zANLI))  \n",
    "p_ANLI = stats.t.cdf( -np.abs( np.mean(zANLI) )/stats.sem(zANLI), df=len(zANLI)-1)\n",
    "\n",
    "#Compare bASELINE and RLR\n",
    "zBALI = zBASE - zLIN\n",
    "ciBALI = stats.t.interval(1-alpha, len(zBALI)-1, loc=np.mean(zBALI), scale=stats.sem(zBALI))  \n",
    "p_BALI = stats.t.cdf( -np.abs( np.mean(zBALI) )/stats.sem(zBALI), df=len(zBALI)-1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ANN/Baseline) Confidence Interval: [-5.342, 0.364] \t P-Value: 0.04362186189472689\n",
      "(ANN/RLR)      Confidence Interval: [302.113, 403.555] \t P-Value: 1.223982608963753e-38\n",
      "(Baseline/RLR) Confidence Interval: [298.498, 402.193] \t\t P-Value: 9.196272004197146e-37\n"
     ]
    }
   ],
   "source": [
    "print('(ANN/Baseline) Confidence Interval: [{0:.3f}, {1:.3f}] \\t P-Value: {2}'.format(*ciANBA[0], *ciANBA[1], *p_ANBA))\n",
    "print('(ANN/RLR)      Confidence Interval: [{0:.3f}, {1:.3f}] \\t P-Value: {2}'.format(*ciANLI[0], *ciANLI[1], *p_ANLI))\n",
    "print('(Baseline/RLR) Confidence Interval: [{0:.3f}, {1:.3f}] \\t\\t P-Value: {2}'.format(*ciBALI[0], *ciBALI[1], *p_BALI))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
